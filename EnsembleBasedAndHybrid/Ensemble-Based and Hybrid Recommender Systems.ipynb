{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we would like to make use of all the knowledge available in different data sources and also use the algorithmic power of various recommender systems to make robust inferences - **Hybrid Recommender Systems**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three primary ways of creating hybrid recommender systems:\n",
    "1. **Ensemble design**: Results from off-the-shelf algorithms are combined into a single and more robust output.\n",
    "2. **Monolithic design**: An integrated recommendation algorithm is created by using various data types.\n",
    "3. **Mixed systems**: These systems use multiple recommendation algorithms as black-boxes, but the items recommended by the various systems are presented togetther side by side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **hybrid system** is used in a broader context than the term **ensemble system**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **hybrid recommendation systems** can be classified into the following categories:\n",
    "1. **Weighted**: The scores of several recommender systems are combined into a sigle unified score by computing the weighted aggregates of the scores from invidual ensemble components.\n",
    "2. **Switching**: The algorithm switches between various recommender systems depending on current needs.\n",
    "3. **Cascade**: One recommender system refines the recommendations given by another.\n",
    "4. **Feature augumentation**: The output of one recommender system is used to create input features for the next.\n",
    "5. **Feature combination**: The features from different data sources are combined and used in the contexr of a single recommender system.\n",
    "6. **Meta-level**: The model used by one recommender system is used as input to another system. Example: Content-based system creates peer groups, then the collaborative filtering system use that peer groups to make the recommendations.\n",
    "7. **Mixed**: Recommendations from several engines are presented to the user at the same time.\n",
    "\n",
    "The first four are ensemble systems, the next two are monolithic systems, and the last one is mixed system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error of a classifier in predicting the dependent variable can be decomposed into three components:\n",
    "1. **Bias**: Every classifier makes its own modeling assumptions about the nature of the decision boundary between classes. When a classifier has high bias, it will make consistently incorrect predictions over particular choices of test instances near the incorrectly modeled-decision boundary.\n",
    "2. **Variance**: Random variations in the choices of the training data will lead to different models. As a result, the dependent variable for a test instance might be inconsistently predicted by different choices of training data sets. Model variance is closely related to overfitting.\n",
    "3. **Noise**: The noise refers to the intrinsic errors in the target class labeling.\n",
    "\n",
    "The expected mean-squared error of a classifier over a set of test instances can be shown to be sum of the bias, variance, and noise:\n",
    "$$ Error = Bias^2 + Variance + Noise $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification ensemble methods such as *bagging* reduce the variance, whereas methods such as *boosting* can reduce the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $R = [r_{uj}]$ be an $m \\times n$ ratings matrix. Let $\\hat{R}_1...\\hat{R}_q$ be the $m \\times n$\n",
    "completely specified ratings matrices, in which the unobserved entries of $R$ are predicted by $q$ different algorithms. Then, for a set of weights $\\alpha_1...\\alpha_q$ , the weighted hybrid creates a combined prediction matrix $\\hat{R} = [\\hat{r}_{uj}]$ as follows:\n",
    "$$ \\hat{R} = \\sum_{i=1}^q \\alpha_i \\hat{R}_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_all_predicted_ratings_matrix(list_matrixs, list_weights):\n",
    "    z = np.multiply(list_weights, np.transpose(list_matrix))\n",
    "    z = np.transpose(z)\n",
    "    \n",
    "    return np.sum(z, axis = 0)/np.sum(list_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to determine the optimal weights, it is necessary to be able to evaluate the\n",
    "effectiveness of a particular combination of weights $\\alpha_1...\\alpha_q$. <br>\n",
    "A simple approach is to hold out a small fraction (e.g., 25%) of the known entries in the $m \\times n$ ratings matrix $R = [r_{uj}]$ and create the prediction matrices $\\hat{R}_1...\\hat{R}_q$ by applying the $q$ different base algorithms on the remaining 75% of the entries in R. The resulting predictions $\\hat{R}_1...\\hat{R}_q$ are then combined to create the ensemble-based prediction $\\hat{R}$. Let the user-item indices $(u,j)$ of these held-out entries be denoted by $H$. The effectiveness of a particular scheme can be evaluated using either the mean-squared error (MSE) or the mean absolute error (MAE) of the predicted matrix over the held-out ratings in $H$. We can use linear regression model to find the most effective values of weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the weights have been learned using linear regression, the individual component models are retrained on the entire training set without any held-out entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization can be added to prevent overfitting. It is also possible to add other con- straints on the various values of αi such as non-negativity or ensuring that they sum to 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, these tech- niques use a simple average of the predictions of different components. It is particularly important to weight the different components when the predicted utility values are on dif- ferent scales, or when some of the ensemble components are much more accurate than others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices for vector\n",
    "def specified_rating_indices(u):\n",
    "    return np.where(np.isfinite(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def get_batch(X, y, batch_size, iteration):\n",
    "    return (X[iteration * batch_size: (iteration + 1) * batch_size], y[iteration * batch_size: (iteration + 1) * batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_weights_using_linear_regression(list_predicted_matrix, original_matrix,\n",
    "                                         batch_size=2, n_epochs=10, learning_rate=0.001):\n",
    "    indices = specified_rating_indices(original_matrix)\n",
    "\n",
    "    X_train = []\n",
    "    for i in range(len(list_predicted_matrix)):\n",
    "        matrix = list_predicted_matrix[i]\n",
    "        X_train.append(matrix[indices])\n",
    "        \n",
    "    X_train = np.transpose(X_train)\n",
    "    y_train = original_matrix[indices]\n",
    "    \n",
    "    n_dimensions = len(list_predicted_matrix)\n",
    "    \n",
    "    # create tensorflow graph\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_dimensions], name='X')\n",
    "    y = tf.placeholder(tf.float32, shape=None, name='y')\n",
    "    \n",
    "#     W = tf.get_variable('W', shape=[n_dimensions, 1], initializer=tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b = tf.Variable(dtype=tf.float32, initial_value=0)\n",
    "#     output = tf.matmul(X, W) + b\n",
    "\n",
    "    output = tf.layers.dense(X, units=1)\n",
    "    \n",
    "    loss = tf.losses.mean_squared_error(output, y)\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            X_train, y_train = shuffle(X_train, y_train)\n",
    "            total_loss = 0\n",
    "            n_iteration = X_train.shape[0] // batch_size\n",
    "            for i in range(n_iteration):\n",
    "                X_batch, y_batch = get_batch(X_train, y_train, batch_size, i)\n",
    "                l, _ = sess.run([loss, optimizer], feed_dict={X: X_batch, y: y_batch})\n",
    "                total_loss += l\n",
    "            \n",
    "            print('Loss: ', total_loss / n_iteration)\n",
    "        \n",
    "        var = [v for v in tf.trainable_variables()][0]\n",
    "        value = sess.run(var)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  19.537912786006927\n",
      "Loss:  15.251693665981293\n",
      "Loss:  11.021173030138016\n",
      "Loss:  8.004278674721718\n",
      "Loss:  7.621613174676895\n",
      "Loss:  7.934566304087639\n",
      "Loss:  6.653058409690857\n",
      "Loss:  8.155106753110886\n",
      "Loss:  7.148072227835655\n",
      "Loss:  6.631481006741524\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2, 9, 4, 5],\n",
    "              [nan, 1, 3, nan, 2]])\n",
    "b = np.array([[2, 2, 4, 5, 6],\n",
    "              [nan, 1, 3, nan, 2]])\n",
    "c = np.array([[3, 4, 5, 6, 7],\n",
    "              [nan, 1, 3, nan, 2]])\n",
    "\n",
    "value = find_weights_using_linear_regression([b, c], a, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0894009 ],\n",
       "       [-0.20308039]], dtype=float32)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various Types of Model Combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are typically two forms of model combinations:\n",
    "1. **Homogeneous data type and model classes**: Different models are applied on the same data. Such an approach is robust because it avoids the specific bias of particular algorithms on a given data set even though all the constituent models belong to the same class\n",
    "2. **Heterogeneous data type and model classes**: Different classes of models are applied to different data sources. The idea is to leverage the complementary knowledge in the various data sources in order to provide the most accurate recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapting Bagging from Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea in bagging is to reduce the variance component of the error in classification. In bagging, $q$ training data sets are created with bootstrapped sampling. In bootstrapped sampling, rows of the data matrix are sampled with replacement in order to create a new training data set of the same size as the original training data set. This new training data set typically contains many duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A particular variant of bagging, known as subagging, subsamples the rows, rather than sampling with replacement. For example, one can simply use all the distinct rows in a bootstrapped sample for training the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Row-wise bootstrapping**: the rows of the ratings matrix $R$ are sampled with replacement to create a new ratings matrix of the same dimensions.\n",
    "2. **Row-wise subsampling**: This approach is similar to row-wise bootstrapping, except that the rows are sampled without replacement. The fraction $f$ of rows sampled is chosen randomly from $(0.1,0.5)$. The number of ensemble components q should be significantly greater than 10 to ensure that all rows are represented.\n",
    "3. **Entry-wise bagging**: the entries of the original ratings matrix are sampled with replacement to create the $q$ different ratings matrices $R_1...R_q$. \n",
    "4. **Entry-wise subsampling**: In entry-wise subsampling, a fraction of the entries are retained at random from the ratings matrix R to create a sampled training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for row-wise bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variant_matrix(ratings_matrix, q):\n",
    "    shape = ratings_matrix.shape\n",
    "    n_users = shape[0]\n",
    "    n_items = shape[1]\n",
    "    \n",
    "    list_new_matrixs = []\n",
    "    list_indice_users = [] \n",
    "    # we need to store the indices because we will compute the average rating for each user\n",
    "    # based on number of times that user appears in new matrix.\n",
    "    \n",
    "    for i in range(q):\n",
    "        random_users = np.random.randint(n_users, size=[n_users])\n",
    "        new_matrix = ratings_matrix[random_users]\n",
    "        \n",
    "        list_indice_users.append(random_users)\n",
    "        list_new_matrixs.append(new_matrix)\n",
    "        \n",
    "    return list_new_matrixs, list_indice_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_rating(list_predicted_matrices, list_indice_users):\n",
    "    n_users = list_predicted_matrices[0].shape[0]\n",
    "    n_items = list_predicted_matrices[0].shape[0]\n",
    "    \n",
    "    average_ratings_matrix = np.zeros(shape=[n_users, n_items])\n",
    "    n_appearances = np.zeros(shape=[n_users])\n",
    "    \n",
    "    for i in range(len(list_predicted_matrices)):\n",
    "        matrix = list_predicted_matrices[i]\n",
    "        for j in range(len(list_indice_users)):\n",
    "            indice = list_indice_users[j]\n",
    "            average_ratings_matrix[indice] += matrix[j]\n",
    "            n_appearances[indice] += 1\n",
    "    \n",
    "    n_appearances = n_appearances.reshape(n_users, -1)\n",
    "    \n",
    "    average_ratings_matrix = np.divide(average_ratings_matrix, n_appearances)\n",
    "    \n",
    "    return average_ratings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(10, 10)\n",
    "matrices, indices = create_variant_matrix(a, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5544684 , 0.48302639, 0.49897061, 0.45261422, 0.41146809,\n",
       "        0.59407013, 0.51869078, 0.40650742, 0.43103446, 0.51774474],\n",
       "       [0.57122743, 0.47417499, 0.50438522, 0.42770641, 0.46337349,\n",
       "        0.56110212, 0.54255025, 0.45046273, 0.38696895, 0.49242176],\n",
       "       [0.60770575, 0.47964033, 0.47405594, 0.40975171, 0.40559398,\n",
       "        0.61054964, 0.54060945, 0.46732633, 0.44447129, 0.52949623],\n",
       "       [0.56329272, 0.47996929, 0.48743222, 0.38879544, 0.41325252,\n",
       "        0.60202025, 0.51795367, 0.50260045, 0.34654813, 0.51158225],\n",
       "       [0.57629426, 0.48050737, 0.4670425 , 0.36075788, 0.39757844,\n",
       "        0.60724309, 0.53803475, 0.48301275, 0.41653515, 0.46425253],\n",
       "       [0.63453612, 0.50996145, 0.44856343, 0.42314875, 0.45070946,\n",
       "        0.56414683, 0.59638614, 0.45267081, 0.45373092, 0.47035176],\n",
       "       [0.56751797, 0.4781543 , 0.48524757, 0.37820407, 0.38739733,\n",
       "        0.62766389, 0.52194064, 0.49616308, 0.40296669, 0.50343461],\n",
       "       [0.54864541, 0.46263895, 0.49253564, 0.39652836, 0.38407235,\n",
       "        0.61895981, 0.49697779, 0.44504307, 0.40889946, 0.50472611],\n",
       "       [0.57551129, 0.47409269, 0.47711895, 0.40634828, 0.3951396 ,\n",
       "        0.62007309, 0.53817493, 0.46137837, 0.44213556, 0.5027213 ],\n",
       "       [0.58381101, 0.48226133, 0.49076646, 0.41481628, 0.42686545,\n",
       "        0.591683  , 0.53898821, 0.4490682 , 0.43345923, 0.49260096]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_average_rating(matrices, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomness Injection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea is to take a base classifier and explicitly inject randomness into the classifier.\n",
    "1. **Injecting randomness into a neighborhood model**: Instead of using the $top-k$ nearest neighbors (users or items) in a user-based or item-based neighborhood model, the $top-\\alpha.k$ neighbors are selected for $\\alpha >> 1$. Then, k elements are randomly selected from these $\\alpha.k$ neighbors.\n",
    "2. **Injecting randomness into a matrix factorization model**: By choosing different initializations, different solutions are often obtained. The combinations of these different solutions often provide more accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Switching Hybrids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switching hybrids are used most commonly in recommender systems in the context of the problem of **model selection**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switching Mechanisms for Cold-Start Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switching mechanisms are often used to handle the cold-start problem, in which one rec- ommender performs better with less data, whereas the other recommender performs better with more data. One might use a knowledge-based recommender, when few ratings are avail- able because knowledge-based recommender systems can function without any ratings, and they are dependent on user specifications of their needs. However, as more ratings become available, one might switch to a collaborative recommender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bucket-of-Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach, a fraction (e.g., 25% to 33%) of the specified entries in the ratings matrix are held out, and various models are applied to the resulting matrix. The held-out entries are then used to evaluate the effectiveness of the model. Once the relevant model has been selected, it is retrained on the entire ratings matrix, and the results are reported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cascade Hybrids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A recommender is allowed to use recommendations of the previous recommender in any way (beyond just direct refinement), and then combine the results to make the final recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Successive Refinement of Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A recommender system successively refines the output of recommendations from the previous iteration. For example, the first recommender can provide a rough rank- ing and also eliminate many of the potential items. The second level of recommendation then uses this rough ranking to further refine it and break ties. The resulting ranking is presented to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In traditional boosting, a sequence of training rounds is used with weighted training examples. The weights in each round are modified depending on the performance of the classifier in the previous round. Specifically, the weights on the training examples with error are increased, whereas the weights on the correctly modeled examples are reduced. As a result, the classifier is biased towards correctly classifying the examples that it was unable to properly classify in the previous round. By using several such rounds, one obtains a sequence of classification models. For a given test instance, all models are applied to it, and the weighted prediction is reported as the relevant one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Augmentation Hybrids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature augmentation hybrid shares a number of intuitive similarities with the stacking ensemble in classification. In stacking, the first level classifier is used to create or aug- ment a set of features for the second level classifier.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using a collaborative system first, it is also possible to use the content-based system first. The basic idea is to use the content-based system to fill in the missing entries of the ratings matrix so that it is no longer sparse. Thus, the missing entries are estimated by the content-based system to create a denser ratings matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, a collaborative recommender is used on the dense ratings matrix to make rating predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-Level Hybrids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a meta-level hybrid, the model learned by one recommender is used as input to the next level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea here is that the content-based peer group is used to determine the most similar users of the target user. Once the peer group has been determined, then the weighted average of the ratings of the peer group are used to determine the predicted ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Combination Hybrids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In feature combination hybrids, the idea is to combine the input data from various sources (e.g., content and collaborative) into a unified representation before applying a predictive algorithm. In most cases, this predictive algorithm is a content-based algorithm that uses collaborative information as additional features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach is to augment a ratings matrix and add columns for keywords in addition to items. Therefore, the ratings matrix becomes an $m \\times (n + d)$ matrix, where n is the number of items and $d$ is the number of keywords. The weights of “keyword items” are based on the weighted aggregation of the descriptions of the items accessed, bought, or rated by the user. A traditional neighborhood or matrix factorization approach can be used with this augmented matrix. The relative weights of the two types of columns can be learned through cross-validation. This type of combination of two optimization models is common in hybrid settings, where the objective function is set up as follows in terms of a parameter vector $\\hat{\\theta}$:\n",
    "$$J = CollaborativeObjective(\\hat{\\theta}) + \\beta ContentObjective(\\hat{\\theta}) + Regularization$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression and Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Minimize\\ J = \\|R − RW\\|^2 + \\beta · \\|R − CW\\|^2 + \\lambda\\|W\\|^2 + \\lambda_1 · \\|W|_1 $$ $$ subject to:$$\n",
    "$$ W≥0$$\n",
    "$$ Diagonal(W ) = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-level Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New meta-features can be extracted from features of a particular type of recommender and then combined within the ensemble model. For example, one can extract meta-level features from a ratings matrix corresponding to the number of ratings given by various users and items. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed Hybrids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main characteristic of mixed recommender systems is that they combine the scores from different components in terms of presentation, rather than in terms of combining the predicted scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
