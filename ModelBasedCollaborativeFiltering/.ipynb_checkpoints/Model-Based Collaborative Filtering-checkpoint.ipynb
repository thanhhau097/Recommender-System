{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyen.thanh.hau/virtualenv/custom_env/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/nguyen.thanh.hau/virtualenv/custom_env/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/nguyen.thanh.hau/virtualenv/custom_env/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/nguyen.thanh.hau/virtualenv/custom_env/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/nguyen.thanh.hau/virtualenv/custom_env/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens 100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('ml-100k/u.data', names=names, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n",
      "1682\n"
     ]
    }
   ],
   "source": [
    "print(n_users)\n",
    "print(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan = np.nan\n",
    "movielens_ratings_matrix = np.zeros((n_users, n_items)) * nan\n",
    "for line in df.itertuples():\n",
    "    movielens_ratings_matrix[line[1]-1, line[2]-1] = line[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.  3.  4. ... nan nan nan]\n",
      " [ 4. nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [ 5. nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan  5. nan ... nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "print(movielens_ratings_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In model-based methods, a summarized model of data is created up front, as with supervised and unsupervised learning methods. Therefore, the training is clearly separated from the prediction phase. <br>\n",
    "Examples of such methods in traditional machine learning include decision trees, rule-based methods, Bayes classifiers, regression models, support vector machines, and neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike data classification, any entry in the ratings matrix maybe missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision and Regression Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini index lies between 0 and 1, with smaller value being more indicative of greater discriminative power: $$ G(S) = 1 - \\sum_{i=1}^r p_i^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Gini(S \\Rightarrow [S_i, S_2] = \\dfrac{n_1.G(S_1) + n_2.G(S_2)}{n_1 + n_2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryMatrix():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def random_init(self, size):\n",
    "        self.matrix = np.random.randint(2, size=size)\n",
    "        \n",
    "    def get_label(self):\n",
    "        return self.matrix[:, -1]\n",
    "    \n",
    "    def get_train_data(self):\n",
    "        return self.matrix[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_matrix = BinaryMatrix()\n",
    "binary_matrix.random_init(size=[100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 1 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [1 0 1 ... 0 1 1]\n",
      " ...\n",
      " [0 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n",
      "[1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1\n",
      " 0 0 1 1 0 1 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0\n",
      " 1 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0]\n",
      "[[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [1 0 1 ... 1 0 1]\n",
      " ...\n",
      " [0 1 1 ... 0 1 1]\n",
      " [0 1 1 ... 1 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(binary_matrix.matrix)\n",
    "print(binary_matrix.get_label())\n",
    "print(binary_matrix.get_train_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyen.thanh.hau/virtualenv/custom_env/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(binary_matrix.get_train_data(),\n",
    "                                                   binary_matrix.get_label(), \n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.sum(y_test == predict_test) / len(y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz\n",
      "  Using cached https://files.pythonhosted.org/packages/47/87/313cd4ea4f75472826acb74c57f94fc83e04ba93e4ccf35656f6b7f502e2/graphviz-0.9-py2.py3-none-any.whl\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.9\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyen.thanh.hau/virtualenv/custom_env/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import sparse_random_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix = sparse_random_matrix(1000, 1000, density=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to choose $j^{th}$ item to be target, and others $n - 1$ columns to be features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=10, n_iter=10, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: $j^{th}$ column is the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = ratings_matrix[:, :-1]\n",
    "y_data = ratings_matrix[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.99437071 1.99214704 1.97315971 1.96586987 1.95468439 1.94150428\n",
      " 1.9347887  1.93256985 1.92155791 1.90991485]\n"
     ]
    }
   ],
   "source": [
    "svd.fit(X_data)\n",
    "print(svd.singular_values_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use Decision tree on density matrix $m \\times d$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_ratings_matrix = svd.transform(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04078747  0.01740403 -0.02456857 ... -0.13284343  0.05258134\n",
      "   0.10191544]\n",
      " [-0.01047693 -0.0370801  -0.08007284 ... -0.02028828 -0.05122547\n",
      "  -0.00393312]\n",
      " [-0.00324058  0.01206909 -0.05224786 ...  0.06357679  0.03219327\n",
      "  -0.10568864]\n",
      " ...\n",
      " [ 0.14103169  0.02498886  0.06968854 ...  0.05991687 -0.0404613\n",
      "   0.09306438]\n",
      " [-0.04791901 -0.05253255 -0.0669215  ... -0.00280977 -0.0266462\n",
      "   0.05423395]\n",
      " [ 0.02091143 -0.01567058 -0.03447271 ...  0.01500747  0.07855035\n",
      "  -0.03599526]]\n"
     ]
    }
   ],
   "source": [
    "print(reduction_ratings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeRegressor()\n",
    "\n",
    "clf.fit(reduction_ratings_matrix, y_data.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.14142136  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.14142136  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.14142136  0.          0.          0.\n",
      "  0.14142136  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.14142136  0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.14142136  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.14142136  0.          0.14142136  0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.14142136  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.14142136  0.\n",
      "  0.          0.          0.          0.          0.         -0.14142136\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.14142136\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.14142136  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.14142136\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.14142136\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.14142136\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.14142136  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -0.14142136  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.14142136  0.          0.          0.          0.\n",
      "  0.          0.          0.         -0.14142136  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.14142136  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.14142136\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.14142136  0.          0.          0.14142136  0.          0.\n",
      "  0.          0.14142136  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.14142136\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.14142136  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.14142136  0.\n",
      "  0.          0.         -0.14142136  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.14142136  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.14142136  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.         -0.14142136  0.          0.\n",
      "  0.          0.          0.         -0.14142136  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.14142136  0.          0.          0.          0.\n",
      "  0.          0.         -0.14142136  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.14142136  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.14142136  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.         -0.14142136  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.14142136\n",
      "  0.          0.          0.         -0.14142136  0.14142136  0.\n",
      "  0.          0.14142136  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.14142136  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.         -0.14142136  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.14142136  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.14142136\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -0.14142136  0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.14142136  0.          0.14142136  0.          0.         -0.14142136\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -0.14142136  0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.14142136  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.14142136\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.14142136  0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.14142136\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.14142136  0.          0.          0.          0.14142136  0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -0.14142136  0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.14142136\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -0.14142136  0.\n",
      "  0.          0.          0.          0.        ]\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(reduction_ratings_matrix))\n",
    "print(clf.predict(reduction_ratings_matrix).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must loop through all items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule-based Collaborative Filtering\n",
    "(recommenderlab in R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a transaction database $ T = \\{ T_1...T_m \\} $ containing $m$ transactions, which are defined on $n$ items $I$. $I$ is the universal set of items, and each transaction $T_i$ is a subset of items in $I$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(\\textbf{support})$ The $support$ of an item set $X \\subseteq I$ is the fraction of transactions in $T$, of which $X$ is a subset <br>\n",
    "If the support of an itemset is at least equal to predefined threshold $s$, then the itemset is said to be frequent. This threshold is referred to as the $minimum support$, these itemset are referred to as $frequent itemsets$ or $frequent patterns$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(\\textbf{Confidence})$ The confidence of the rule $X \\Rightarrow Y$ is the conditional probability that a transaction in $T$ contains $Y$, given that it also contains $X$. Therefore, the confidence is obtained by dividing the support of $X \\cup Y$ with the support of $X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(\\textbf{Association Rules})$ A rule $X \\Rightarrow Y$ is said to be an association rule at a minimum support of $s$ and minimum confidence of $c$, if the following two conditions are satisfied:<br>\n",
    "1. The support of $X \\cup Y$ is at least $s$\n",
    "2. The confidence of $X \\Rightarrow Y$ Ã­ at least $c$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive  Bayes Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes Rule: $$ P(A|B) = \\dfrac{P(A).P(B|A)}{P(B)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using an Arbitrary Classification Model as a Blackbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to initialize the missing entries in the matrix with row averages, column averages, or with any simple collaborative filtering algorithm => remove bias, then fill 0 in the missing entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following two steps iterative approach:\n",
    "1. Use algorithm $A$ to estimate the missing entries of each column by setting it as the target variable and the remaining columns as the feature variables. For the remaining columns, use the current set of filled in values to create a complete matrix of feature variables. The observed ratings in the target column are used for training, the the missing ratings are predicted.\n",
    "2. Update all the missing entries based on the prediction of algorithm $A$ on each target colum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firsly, we will substract the rating values by row averages, then fill 0 in the missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specified_rating_indices(u):\n",
    "    return list(map(tuple, np.where(np.isfinite(u))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean rating for each user i using his specified rating\n",
    "def mean(u):\n",
    "    specified_ratings = u[specified_rating_indices(u)]#u[np.isfinite(u)]\n",
    "    m = sum(specified_ratings)/np.shape(specified_ratings)[0]\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_user_mean_ratings(ratings_matrix):\n",
    "    return np.array([mean(ratings_matrix[u, :]) for u in range(ratings_matrix.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_centered_ratings_matrix(ratings_matrix):\n",
    "    users_mean_rating = all_user_mean_ratings(ratings_matrix)\n",
    "    mean_centered_ratings_matrix = ratings_matrix - np.reshape(users_mean_rating, [-1, 1])\n",
    "    return mean_centered_ratings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyen.thanh.hau/virtualenv/custom_env/lib/python3.5/site-packages/ipykernel_launcher.py:3: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "mean_centered_ratings_matrix = get_mean_centered_ratings_matrix(movielens_ratings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.38970588 -0.61029412  0.38970588 ...         nan         nan\n",
      "          nan]\n",
      " [ 0.29032258         nan         nan ...         nan         nan\n",
      "          nan]\n",
      " [        nan         nan         nan ...         nan         nan\n",
      "          nan]\n",
      " ...\n",
      " [ 0.95454545         nan         nan ...         nan         nan\n",
      "          nan]\n",
      " [        nan         nan         nan ...         nan         nan\n",
      "          nan]\n",
      " [        nan  1.58928571         nan ...         nan         nan\n",
      "          nan]]\n"
     ]
    }
   ],
   "source": [
    "print(mean_centered_ratings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_zero_in_nan(matrix_2d):    \n",
    "    for i in range(len(matrix_2d)):\n",
    "        row = matrix_2d[i]\n",
    "        \n",
    "        for j in range(len(row)):\n",
    "            if np.isnan(row[j]):\n",
    "                matrix_2d[i][j] = 0\n",
    "    \n",
    "    return matrix_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_average_rating_matrix = fill_zero_in_nan(mean_centered_ratings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.38970588 -0.61029412  0.38970588 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.29032258  0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.95454545  0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          1.58928571  0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(row_average_rating_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we choose a column to be the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To easily using neural network, we should find the item which is rated most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "m = 0\n",
    "m_index = 0\n",
    "\n",
    "for i in range(n_items):\n",
    "    y_i = movielens_ratings_matrix[:, i]\n",
    "    total = 0\n",
    "\n",
    "    for element in y_i:\n",
    "        if not np.isnan(element):\n",
    "            total = total + 1\n",
    "    if total > m:\n",
    "        m = total\n",
    "        m_index = i\n",
    "print(m)\n",
    "print(m_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example, we will choose \n",
    "target_index = 49\n",
    "\n",
    "X_data = row_average_rating_matrix[:, :target_index]\n",
    "X_data = np.concatenate((X_data, row_average_rating_matrix[:, (target_index + 1):]), axis=1)\n",
    "\n",
    "y_data = row_average_rating_matrix[:, target_index]\n",
    "y_data_original = movielens_ratings_matrix[:, target_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = []\n",
    "test_indices = []\n",
    "\n",
    "for i in range(len(y_data_original)):\n",
    "    if not np.isnan(y_data_original[i]):\n",
    "        train_indices.append(i)\n",
    "    else:\n",
    "        test_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_data[train_indices]\n",
    "y_train = y_data[train_indices]\n",
    "\n",
    "X_test = X_data[test_indices]\n",
    "y_test = y_data[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(524, 1681)\n",
      "(59, 1681)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def get_batch(X, y, iteration, batch_size):\n",
    "    indices = range(iteration * batch_size, (iteration + 1) * batch_size)\n",
    "    \n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a neural network to train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_items-1], name='X')\n",
    "y = tf.placeholder(tf.float32, shape=None, name='y')\n",
    "\n",
    "network = tf.layers.dense(inputs=X, activation=tf.nn.relu, units=256)\n",
    "network = tf.layers.dense(inputs=network, activation=tf.nn.relu, units=128)\n",
    "network = tf.layers.dense(inputs=network, activation=tf.nn.relu, units=128)\n",
    "network = tf.layers.dense(inputs=network, activation=tf.nn.relu, units=128)\n",
    "network = tf.layers.dense(inputs=network, activation=tf.nn.relu, units=32)\n",
    "\n",
    "outputs = tf.layers.dense(inputs=network, units=1)\n",
    "\n",
    "loss = tf.losses.mean_squared_error(labels=y, predictions=outputs)\n",
    "\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "train_op = train_op.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 \t Training loss:  0.9062139717432168 \t Validation loss:  0.8431002\n",
      "Epoch  1 \t Training loss:  0.8141486291701977 \t Validation loss:  0.7977409\n",
      "Epoch  2 \t Training loss:  0.7972378898125428 \t Validation loss:  0.78386694\n",
      "Epoch  3 \t Training loss:  0.7884282235915844 \t Validation loss:  0.7754402\n",
      "Epoch  4 \t Training loss:  0.7815012198228103 \t Validation loss:  0.76904607\n",
      "Epoch  5 \t Training loss:  0.7757280186964916 \t Validation loss:  0.76381326\n",
      "Epoch  6 \t Training loss:  0.7708515685338241 \t Validation loss:  0.75945324\n",
      "Epoch  7 \t Training loss:  0.7666424684799634 \t Validation loss:  0.75575244\n",
      "Epoch  8 \t Training loss:  0.7629968927456783 \t Validation loss:  0.75261575\n",
      "Epoch  9 \t Training loss:  0.7597527728630946 \t Validation loss:  0.7498925\n",
      "Epoch  10 \t Training loss:  0.7569194896863057 \t Validation loss:  0.74752337\n",
      "Epoch  11 \t Training loss:  0.7543559283018112 \t Validation loss:  0.7454361\n",
      "Epoch  12 \t Training loss:  0.7520241019817498 \t Validation loss:  0.7436055\n",
      "Epoch  13 \t Training loss:  0.7499124105160053 \t Validation loss:  0.7420072\n",
      "Epoch  14 \t Training loss:  0.7479839451037921 \t Validation loss:  0.74058765\n",
      "Epoch  15 \t Training loss:  0.7461726096960214 \t Validation loss:  0.73931926\n",
      "Epoch  16 \t Training loss:  0.7445037094446328 \t Validation loss:  0.73819983\n",
      "Epoch  17 \t Training loss:  0.7429247360963088 \t Validation loss:  0.73719066\n",
      "Epoch  18 \t Training loss:  0.741428653551982 \t Validation loss:  0.73630375\n",
      "Epoch  19 \t Training loss:  0.7399757240827267 \t Validation loss:  0.7354998\n",
      "Epoch  20 \t Training loss:  0.738608943269803 \t Validation loss:  0.7347898\n",
      "Epoch  21 \t Training loss:  0.7373355782949007 \t Validation loss:  0.73417443\n",
      "Epoch  22 \t Training loss:  0.7361018882347987 \t Validation loss:  0.73362446\n",
      "Epoch  23 \t Training loss:  0.7349408929164593 \t Validation loss:  0.7331384\n",
      "Epoch  24 \t Training loss:  0.7338124183508066 \t Validation loss:  0.7327168\n",
      "Epoch  25 \t Training loss:  0.7327329825896484 \t Validation loss:  0.7323335\n",
      "Epoch  26 \t Training loss:  0.7316948090608303 \t Validation loss:  0.7320139\n",
      "Epoch  27 \t Training loss:  0.7306923112043968 \t Validation loss:  0.7317279\n",
      "Epoch  28 \t Training loss:  0.729720627115323 \t Validation loss:  0.73148257\n",
      "Epoch  29 \t Training loss:  0.7287774422994027 \t Validation loss:  0.7312755\n",
      "Epoch  30 \t Training loss:  0.7278677116219814 \t Validation loss:  0.73109436\n",
      "Epoch  31 \t Training loss:  0.7269681577499096 \t Validation loss:  0.73093945\n",
      "Epoch  32 \t Training loss:  0.7260984786427938 \t Validation loss:  0.73082125\n",
      "Epoch  33 \t Training loss:  0.7252436696336819 \t Validation loss:  0.7307086\n",
      "Epoch  34 \t Training loss:  0.7244205642205018 \t Validation loss:  0.73063016\n",
      "Epoch  35 \t Training loss:  0.7236241355538369 \t Validation loss:  0.7305791\n",
      "Epoch  36 \t Training loss:  0.7228367500580274 \t Validation loss:  0.73054034\n",
      "Epoch  37 \t Training loss:  0.7220814553590921 \t Validation loss:  0.7305223\n",
      "Epoch  38 \t Training loss:  0.7213248339983133 \t Validation loss:  0.73050886\n",
      "Epoch  39 \t Training loss:  0.7205916936580952 \t Validation loss:  0.7305157\n",
      "Epoch  40 \t Training loss:  0.7198727999742215 \t Validation loss:  0.7305385\n",
      "Epoch  41 \t Training loss:  0.7191827388910147 \t Validation loss:  0.73056626\n",
      "Epoch  42 \t Training loss:  0.7184994145081594 \t Validation loss:  0.73063403\n",
      "Epoch  43 \t Training loss:  0.7178329330224257 \t Validation loss:  0.7306828\n",
      "Epoch  44 \t Training loss:  0.7171676456928253 \t Validation loss:  0.7307501\n",
      "Epoch  45 \t Training loss:  0.716524192576225 \t Validation loss:  0.7308256\n",
      "Epoch  46 \t Training loss:  0.7158770850071541 \t Validation loss:  0.7309069\n",
      "Epoch  47 \t Training loss:  0.7152445763349533 \t Validation loss:  0.73100954\n",
      "Epoch  48 \t Training loss:  0.7146181057278926 \t Validation loss:  0.7311008\n",
      "Epoch  49 \t Training loss:  0.7140083358838007 \t Validation loss:  0.73122174\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "batch_size = 8\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = 0\n",
    "        \n",
    "        for i in range(len(X_train) // batch_size):\n",
    "            X_batch, y_batch = get_batch(X_train, y_train, iteration=i, batch_size=batch_size)\n",
    "\n",
    "            _, loss_batch = sess.run([train_op, loss], feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "            train_loss = train_loss + loss_batch\n",
    "    \n",
    "        train_loss = train_loss / (len(X_train) // batch_size)\n",
    "        val_loss = sess.run(loss, feed_dict={X: X_val, y: y_val})\n",
    "        \n",
    "        print(\"Epoch \", epoch, \"\\t Training loss: \", train_loss, \"\\t Validation loss: \", val_loss)\n",
    "    \n",
    "    y_predict = sess.run(outputs, feed_dict={X: X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8244265 ]\n",
      " [0.7992963 ]\n",
      " [0.7151614 ]\n",
      " [0.6072709 ]\n",
      " [0.57653856]\n",
      " [0.7129195 ]\n",
      " [0.65517956]\n",
      " [0.69452715]\n",
      " [0.6158813 ]\n",
      " [0.67767125]\n",
      " [0.70560974]\n",
      " [0.5704838 ]\n",
      " [1.0164324 ]\n",
      " [0.6562325 ]\n",
      " [0.5125287 ]\n",
      " [0.6158452 ]\n",
      " [0.660842  ]\n",
      " [0.6488246 ]\n",
      " [0.5540173 ]\n",
      " [0.6008504 ]\n",
      " [0.64987296]\n",
      " [0.6109796 ]\n",
      " [0.75217277]\n",
      " [0.9310632 ]\n",
      " [0.6544408 ]\n",
      " [0.71324915]\n",
      " [0.70407903]\n",
      " [0.57499236]\n",
      " [0.6338813 ]\n",
      " [0.67935055]\n",
      " [0.6699575 ]\n",
      " [0.5173856 ]\n",
      " [0.6108985 ]\n",
      " [0.59659684]\n",
      " [0.6361554 ]\n",
      " [0.5902808 ]\n",
      " [0.6092829 ]\n",
      " [0.6492711 ]\n",
      " [0.7651989 ]\n",
      " [0.60959125]\n",
      " [0.79862213]\n",
      " [0.76518697]\n",
      " [0.70256627]\n",
      " [0.8029071 ]\n",
      " [0.7577631 ]\n",
      " [0.74950796]\n",
      " [0.60052365]\n",
      " [0.7353918 ]\n",
      " [0.6845374 ]\n",
      " [0.6555613 ]\n",
      " [0.6791742 ]\n",
      " [0.6154612 ]\n",
      " [0.5981364 ]\n",
      " [0.5915795 ]\n",
      " [0.5863832 ]\n",
      " [0.7664485 ]\n",
      " [0.64865434]\n",
      " [0.69487214]\n",
      " [0.7047136 ]\n",
      " [0.5763406 ]\n",
      " [1.0678904 ]\n",
      " [0.61312014]\n",
      " [0.8978949 ]\n",
      " [0.7241105 ]\n",
      " [0.59339255]\n",
      " [0.6212857 ]\n",
      " [0.83165914]\n",
      " [0.65316355]\n",
      " [0.602185  ]\n",
      " [0.7173874 ]\n",
      " [0.6550926 ]\n",
      " [0.6485914 ]\n",
      " [0.7009134 ]\n",
      " [0.5871625 ]\n",
      " [0.95039254]\n",
      " [0.65664434]\n",
      " [0.7075625 ]\n",
      " [0.62259215]\n",
      " [0.8319635 ]\n",
      " [0.75410753]\n",
      " [0.64899194]\n",
      " [0.7705099 ]\n",
      " [0.5565039 ]\n",
      " [0.72967815]\n",
      " [0.6506717 ]\n",
      " [0.9591959 ]\n",
      " [0.8265558 ]\n",
      " [0.6530044 ]\n",
      " [0.8337263 ]\n",
      " [0.7871098 ]\n",
      " [0.6742729 ]\n",
      " [0.6283262 ]\n",
      " [0.72366774]\n",
      " [0.83210725]\n",
      " [0.74144465]\n",
      " [0.6862013 ]\n",
      " [0.7707123 ]\n",
      " [0.6758341 ]\n",
      " [0.8900576 ]\n",
      " [0.64725584]\n",
      " [0.713244  ]\n",
      " [0.7386803 ]\n",
      " [0.6708281 ]\n",
      " [0.6387953 ]\n",
      " [0.8019932 ]\n",
      " [0.66560996]\n",
      " [0.9564649 ]\n",
      " [0.66392654]\n",
      " [0.6163521 ]\n",
      " [0.7390242 ]\n",
      " [0.5623276 ]\n",
      " [0.515769  ]\n",
      " [0.78369904]\n",
      " [0.6535292 ]\n",
      " [0.71348083]\n",
      " [0.80461806]\n",
      " [0.6384571 ]\n",
      " [0.710989  ]\n",
      " [0.7585273 ]\n",
      " [0.63935405]\n",
      " [0.64305747]\n",
      " [0.6664193 ]\n",
      " [0.7082595 ]\n",
      " [0.8094216 ]\n",
      " [0.5895978 ]\n",
      " [0.91816956]\n",
      " [0.7827163 ]\n",
      " [0.58147323]\n",
      " [0.6430549 ]\n",
      " [0.7806782 ]\n",
      " [0.641201  ]\n",
      " [0.7323192 ]\n",
      " [0.7331485 ]\n",
      " [0.61005986]\n",
      " [0.8669432 ]\n",
      " [0.6443966 ]\n",
      " [0.75845194]\n",
      " [0.69451916]\n",
      " [0.6779437 ]\n",
      " [0.63851506]\n",
      " [0.704751  ]\n",
      " [0.9404647 ]\n",
      " [0.44628072]\n",
      " [0.5729012 ]\n",
      " [0.63912004]\n",
      " [0.8065321 ]\n",
      " [0.74818444]\n",
      " [0.7615769 ]\n",
      " [0.66832036]\n",
      " [0.6662554 ]\n",
      " [0.69458675]\n",
      " [0.74787974]\n",
      " [0.6190599 ]\n",
      " [0.6527304 ]\n",
      " [0.8102351 ]\n",
      " [0.6322173 ]\n",
      " [0.55958354]\n",
      " [0.58277327]\n",
      " [0.6222798 ]\n",
      " [0.6464578 ]\n",
      " [0.70964813]\n",
      " [0.695672  ]\n",
      " [0.580298  ]\n",
      " [0.6862174 ]\n",
      " [0.6878458 ]\n",
      " [0.6697688 ]\n",
      " [0.6077472 ]\n",
      " [0.595921  ]\n",
      " [0.59938496]\n",
      " [0.762952  ]\n",
      " [0.48055202]\n",
      " [0.7961552 ]\n",
      " [0.5929915 ]\n",
      " [0.62537754]\n",
      " [0.6719201 ]\n",
      " [0.66476065]\n",
      " [0.6352408 ]\n",
      " [0.80287963]\n",
      " [0.62839454]\n",
      " [0.81518173]\n",
      " [0.70728   ]\n",
      " [0.612121  ]\n",
      " [0.708718  ]\n",
      " [0.6680522 ]\n",
      " [0.61022335]\n",
      " [0.7455284 ]\n",
      " [0.5994762 ]\n",
      " [0.7142737 ]\n",
      " [0.7106646 ]\n",
      " [0.75993997]\n",
      " [0.6592476 ]\n",
      " [0.6311972 ]\n",
      " [0.62358934]\n",
      " [0.7387524 ]\n",
      " [0.6410963 ]\n",
      " [0.81056875]\n",
      " [0.6511332 ]\n",
      " [0.6159518 ]\n",
      " [0.6437227 ]\n",
      " [0.7156056 ]\n",
      " [0.79297465]\n",
      " [0.84889454]\n",
      " [0.7659704 ]\n",
      " [0.88982826]\n",
      " [0.66550034]\n",
      " [0.5603693 ]\n",
      " [0.6103161 ]\n",
      " [0.60150796]\n",
      " [0.7922813 ]\n",
      " [0.703335  ]\n",
      " [0.85927826]\n",
      " [0.7568217 ]\n",
      " [0.6190568 ]\n",
      " [0.67124206]\n",
      " [0.79171187]\n",
      " [0.7973698 ]\n",
      " [0.6179278 ]\n",
      " [0.89488196]\n",
      " [0.8825424 ]\n",
      " [0.90510905]\n",
      " [0.6666623 ]\n",
      " [0.7248623 ]\n",
      " [0.68140346]\n",
      " [0.7497686 ]\n",
      " [0.70350295]\n",
      " [0.76639825]\n",
      " [0.6335147 ]\n",
      " [0.8701697 ]\n",
      " [0.7422608 ]\n",
      " [0.62506676]\n",
      " [0.79796535]\n",
      " [0.4999513 ]\n",
      " [0.64888424]\n",
      " [0.6059252 ]\n",
      " [0.80365145]\n",
      " [0.47071016]\n",
      " [0.5466205 ]\n",
      " [0.6134235 ]\n",
      " [0.71311593]\n",
      " [0.68072045]\n",
      " [0.8466838 ]\n",
      " [0.69689775]\n",
      " [0.6464718 ]\n",
      " [0.6770868 ]\n",
      " [0.68240565]\n",
      " [0.67282325]\n",
      " [0.5646196 ]\n",
      " [0.9057384 ]\n",
      " [0.8330483 ]\n",
      " [0.56014293]\n",
      " [0.54403603]\n",
      " [0.7689278 ]\n",
      " [0.83844215]\n",
      " [0.6730297 ]\n",
      " [0.8189837 ]\n",
      " [0.60623664]\n",
      " [0.64172006]\n",
      " [0.63067573]\n",
      " [0.82038087]\n",
      " [0.62647706]\n",
      " [0.6941603 ]\n",
      " [0.64256763]\n",
      " [0.70598745]\n",
      " [0.9401071 ]\n",
      " [0.6251235 ]\n",
      " [0.6011743 ]\n",
      " [0.68229085]\n",
      " [0.6766881 ]\n",
      " [0.6235728 ]\n",
      " [0.5860985 ]\n",
      " [0.5056154 ]\n",
      " [0.6626304 ]\n",
      " [0.7219313 ]\n",
      " [0.7071284 ]\n",
      " [0.6194811 ]\n",
      " [0.78036815]\n",
      " [0.710517  ]\n",
      " [0.7435139 ]\n",
      " [0.70538265]\n",
      " [0.6247729 ]\n",
      " [0.9233182 ]\n",
      " [0.6597436 ]\n",
      " [0.67769045]\n",
      " [0.6519616 ]\n",
      " [0.6297176 ]\n",
      " [0.6752228 ]\n",
      " [0.5704009 ]\n",
      " [0.65614027]\n",
      " [0.60456824]\n",
      " [0.69500405]\n",
      " [0.6072669 ]\n",
      " [0.5832129 ]\n",
      " [0.6209568 ]\n",
      " [0.84257483]\n",
      " [0.7162569 ]\n",
      " [0.7469083 ]\n",
      " [0.55742013]\n",
      " [0.531251  ]\n",
      " [0.64007086]\n",
      " [0.67190886]\n",
      " [0.5783062 ]\n",
      " [0.6414171 ]\n",
      " [0.5793525 ]\n",
      " [0.57086784]\n",
      " [0.6388676 ]\n",
      " [0.6602574 ]\n",
      " [0.6357898 ]\n",
      " [0.61276066]\n",
      " [0.7780922 ]\n",
      " [0.66602296]\n",
      " [0.6120361 ]\n",
      " [0.7302308 ]\n",
      " [0.5747618 ]\n",
      " [0.6910425 ]\n",
      " [0.66890234]\n",
      " [0.69476676]\n",
      " [0.69075453]\n",
      " [0.7096014 ]\n",
      " [0.6595515 ]\n",
      " [0.7195117 ]\n",
      " [0.7219427 ]\n",
      " [0.60209125]\n",
      " [0.6558904 ]\n",
      " [0.59396046]\n",
      " [0.69189394]\n",
      " [0.70585877]\n",
      " [0.617162  ]\n",
      " [0.6738458 ]\n",
      " [0.6526661 ]\n",
      " [0.72537076]\n",
      " [0.97300357]\n",
      " [0.6030387 ]\n",
      " [0.63796204]\n",
      " [0.58715147]\n",
      " [0.5673448 ]\n",
      " [0.6265181 ]\n",
      " [0.60424143]\n",
      " [0.7719137 ]\n",
      " [0.50615245]\n",
      " [0.6067857 ]\n",
      " [0.6337786 ]\n",
      " [0.67089844]\n",
      " [0.64159954]\n",
      " [0.67644703]\n",
      " [0.62563556]\n",
      " [0.7205606 ]\n",
      " [0.69259554]\n",
      " [0.68761516]\n",
      " [0.58595866]\n",
      " [0.6333838 ]\n",
      " [0.77392405]\n",
      " [0.65511274]\n",
      " [0.6388462 ]\n",
      " [0.59893095]\n",
      " [0.73277086]\n",
      " [0.6994191 ]\n",
      " [0.6964677 ]\n",
      " [0.6728147 ]\n",
      " [0.6429855 ]\n",
      " [0.62702304]]\n"
     ]
    }
   ],
   "source": [
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "May be this result is not good as expected, but we can use this approach. <br>\n",
    "We've predict ratings for one items, it is similar for other items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Factor Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-Rank Intuition for Latent Factor Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rank-k ratings matrix $R$ with size $m \\times n$ can always be expressed in the following product form of rank-k factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
