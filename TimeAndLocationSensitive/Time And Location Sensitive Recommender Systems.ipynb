{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many real scenarios, the buying and rating behaviors of customers are associated with temporal information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time can be viewed from a recency and forecasting perspective, or from a contextual (e.g., seasonal) perspective. From a recency perspective, the basic idea is that recent ratings are more important than older ratings. In the contextual perspective, various periodic aspects, such as season or month, may be used.\n",
    "\n",
    "When time is viewed as a continuous variable, the recommendations are often created as functions of time. The temporal context can be viewed from a periodic, recency, or modeling point of view.\n",
    "\n",
    "Time can be treated as a modeling variable by explicitly expressing the predicted ratings as a function of time. The parameters of this function can be learned in a data-driven manner by minimizing the squared error of the predicted ratings with respect to the observed ratings. An example of such a model is time-SVD++, which expresses the predicted ratings as a function of temporally parameterized biases and factor matrices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporal information can be used in one of two ways in order to improve the effectiveness of prediction:\n",
    "1. Recency-based models: Some models consider recent ratings more important than older ratings. In these cases, window-based and decay-based models are used for more accurate prediction.\n",
    "2. Periodic context-based models: In periodic context-based models, the specific property of a period, such as the time at the level of specificity of the hour, day, week, month, or sea- son, is used to perform the recommendation. \n",
    "3. Models that explicitly use time as an independent variable: A recent approach, referred to as time-SVD++, uses time as an independent variable within the modeling process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recency-Based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decay-Based Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In decay-based methods, a time-stamp $t_{uj}$ is associated with each observed rating of user $u$ and item $j$ in the $m \\times n$ ratings matrix $R$. It is assumed that all recommendations should be made at a future time $t_f$ . This future time is also referred to as the target time. Then, the weight $w_{uj}(t_f)$ of the rating $r_{uj}$ at target time $t_f$ is defined with the use of a decay function, that penalizes larger distances between $t_{uj}$ and $t_f$ . A decay function is the exponential function: \n",
    "$$ w_{uj}(t_f) = exp[-\\lambda (t_f - t_{uj})]$$\n",
    "\n",
    "The decay-rate $\\lambda$ is a user-defined parameter that regulates the importance of time. Larger values of $\\lambda$ de-emphasize older ratings to a greater degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then:\n",
    "$$ \\hat{r}_{uj} (t_f) = \\mu_u + \\dfrac{\\sum_{v \\in P_u(j)} w_{vj} (t_f) .Sim(u, v).(r_{vj} - \\mu_v)}{\\sum_{v \\in P_u(j)} w_{vj} (t_f) .|Sim(u, v)|} $$\n",
    "\n",
    "Here, $P_u(j)$ represents the $k$ closest users to user $u$ that have specified ratings for item $j$. The optimal value of λ can be learned using cross-validation methods,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example in MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir_path = os.path.abspath(os.path.join('', os.pardir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv(os.path.join(dir_path, 'data/ml-100k/u.data'), names=names, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan = np.nan\n",
    "\n",
    "time_matrix = np.zeros((n_users, n_items)) * nan\n",
    "ratings_matrix = np.zeros((n_users, n_items)) * nan\n",
    "\n",
    "for line in df.itertuples():\n",
    "    ratings_matrix[line[1]-1, line[2]-1] = line[3]\n",
    "    time_matrix[line[1]-1, line[2]-1] = line[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get test data\n",
    "We need to get the test data with the newest time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_time_matrix = np.reshape(time_matrix, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_time_indices = np.argsort(flatten_time_matrix) # decreasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_test_indices = sorted_time_indices[:5000]\n",
    "flatten_train_indices = sorted_time_indices[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(flatten_indices):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for indices in flatten_indices:\n",
    "        x = indices // n_items\n",
    "        y = indices % n_items\n",
    "        \n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        \n",
    "    return [tuple(X), tuple(Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = get_indices(flatten_test_indices)\n",
    "train_indices = get_indices(flatten_train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings_matrix(original_matrix, indices):\n",
    "    shape = np.shape(original_matrix)\n",
    "    matrix = np.ones(shape) * nan\n",
    "    \n",
    "    for i in range(len(indices[0])):\n",
    "        x = indices[0][i]\n",
    "        y = indices[1][i]\n",
    "        \n",
    "        matrix[x][y] = original_matrix[x][y]\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings_matrix = get_ratings_matrix(ratings_matrix, train_indices)\n",
    "test_ratings_matrix = get_ratings_matrix(ratings_matrix, test_indices)\n",
    "\n",
    "train_time_matrix = get_ratings_matrix(time_matrix, train_indices)\n",
    "test_time_matrix = get_ratings_matrix(time_matrix, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices for vector\n",
    "def specified_rating_indices(u):\n",
    "    return np.where(np.isfinite(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean rating for each user i using his specified rating\n",
    "def mean(u):\n",
    "    # may use specified_rating_indices but use more time\n",
    "    specified_ratings = u[specified_rating_indices(u)]#u[np.isfinite(u)]\n",
    "    if np.shape(specified_ratings)[0] == 0: return nan\n",
    "    m = sum(specified_ratings)/np.shape(specified_ratings)[0]\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_user_mean_ratings(ratings_matrix):\n",
    "    return np.array([mean(ratings_matrix[u, :]) for u in range(ratings_matrix.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_centered_ratings_matrix(ratings_matrix):\n",
    "    users_mean_rating = all_user_mean_ratings(ratings_matrix)\n",
    "    mean_centered_ratings_matrix = ratings_matrix - np.reshape(users_mean_rating, [-1, 1])\n",
    "    return mean_centered_ratings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_centered_ratings_matrix = get_mean_centered_ratings_matrix(train_ratings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson(u, v):\n",
    "    mean_u = mean(u)\n",
    "    mean_v = mean(v)\n",
    "    \n",
    "    specified_rating_indices_u = set(specified_rating_indices(u)[0])\n",
    "    specified_rating_indices_v = set(specified_rating_indices(v)[0])\n",
    "    \n",
    "    mutually_specified_ratings_indices = specified_rating_indices_u.intersection(specified_rating_indices_v)\n",
    "    mutually_specified_ratings_indices = list(mutually_specified_ratings_indices)\n",
    "    \n",
    "    u_mutually = u[mutually_specified_ratings_indices]\n",
    "    v_mutually = v[mutually_specified_ratings_indices]\n",
    "      \n",
    "    centralized_mutually_u = u_mutually - mean_u\n",
    "    centralized_mutually_v = v_mutually - mean_v\n",
    "#     print(np.sqrt(np.sum(np.square(centralized_mutually_u))))\n",
    "\n",
    "    result = np.sum(np.multiply(centralized_mutually_u, centralized_mutually_v)) \n",
    "    result = result / (np.sqrt(np.sum(np.square(centralized_mutually_u))) * np.sqrt(np.sum(np.square(centralized_mutually_v))))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_centered(u):\n",
    "    return u - mean(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_similarity_value_for(u_index, ratings_matrix, func):\n",
    "    user_ratings = ratings_matrix[u_index, :]\n",
    "    similarity_value = np.array([func(ratings_matrix[i, :], user_ratings) for i in range(ratings_matrix.shape[0])])\n",
    "    return similarity_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def get_user_similarity_matrix(ratings_matrix, func):\n",
    "    similarity_matrix = []\n",
    "    for u_index in tqdm(range(ratings_matrix.shape[0])):\n",
    "        similarity_value = get_user_similarity_value_for(u_index, ratings_matrix, func)\n",
    "        similarity_matrix.append(similarity_value)\n",
    "    return np.array(similarity_matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/943 [00:00<?, ?it/s]/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "100%|██████████| 943/943 [01:41<00:00,  9.26it/s]\n"
     ]
    }
   ],
   "source": [
    "user_similarity_matrix = get_user_similarity_matrix(train_ratings_matrix, pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_mean_rating = all_user_mean_ratings(train_ratings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_month(d1, d2):\n",
    "    d1 = datetime.fromtimestamp(d1)\n",
    "    d2 = datetime.fromtimestamp(d2)\n",
    "    return (d1.year - d2.year) * 12 + d1.month - d2.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weight by diff of months\n",
    "\n",
    "def weight_for_rating(lambda_param, rating_time, current_time):\n",
    "    months = diff_month(rating_time, current_time)\n",
    "    return np.exp(-lambda_param*months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(u_index, i_index, k):\n",
    "    \n",
    "    similarity_value = user_similarity_matrix[u_index]\n",
    "    sorted_users_similar = np.argsort(similarity_value)\n",
    "    sorted_users_similar = np.flip(sorted_users_similar, axis=0)\n",
    "        \n",
    "    # only for this item\n",
    "    users_rated_item = specified_rating_indices(ratings_matrix[:, i_index])[0]\n",
    "\n",
    "    set_2 = frozenset(users_rated_item)\n",
    "    ranked_similar_user_rated_item = [u for u in sorted_users_similar if u in set_2] \n",
    "    \n",
    "    if k < len(ranked_similar_user_rated_item):\n",
    "        top_k_similar_user = ranked_similar_user_rated_item[0:k]   \n",
    "    else:\n",
    "        top_k_similar_user = np.array(ranked_similar_user_rated_item)\n",
    "            \n",
    "    # replace with mean_centered for user\n",
    "    \n",
    "    ratings_in_item = mean_centered_ratings_matrix[:, i_index]\n",
    "    top_k_ratings = ratings_in_item[top_k_similar_user]\n",
    "    \n",
    "    top_k_similarity_value = similarity_value[top_k_similar_user]\n",
    "\n",
    "    r_hat = users_mean_rating[u_index] + np.sum(top_k_ratings * top_k_similarity_value)/np.sum(np.abs(top_k_similarity_value))\n",
    "    return r_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_ratings_matrix():\n",
    "    predicted_ratings = []\n",
    "    for u_index in tqdm(range(n_users)):\n",
    "        user_ratings = []\n",
    "        for i_index in range(n_items):\n",
    "#             rating = ratings_matrix[u_index][i_index]\n",
    "#             if np.isnan(rating):\n",
    "            rating = predict(u_index, i_index, 100)\n",
    "            user_ratings.append(rating)\n",
    "        predicted_ratings.append(user_ratings)\n",
    "    return predicted_ratings            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/943 [00:01<05:08,  3.04it/s]/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n",
      "100%|██████████| 943/943 [05:18<00:00,  2.96it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted_ratings = get_predicted_ratings_matrix()\n",
    "predicted_ratings = np.array(predicted_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
